{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c490aab6-378c-474c-bdaf-1d27f220e065",
   "metadata": {
    "id": "c490aab6-378c-474c-bdaf-1d27f220e065"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#import cv2\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Dropout2d\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf888b97-c936-4d4d-b35e-2860fbf40bdf",
   "metadata": {
    "id": "bf888b97-c936-4d4d-b35e-2860fbf40bdf"
   },
   "outputs": [],
   "source": [
    "# DataLoader Class\n",
    "# if BATCH_SIZE = N, dataloader returns images tensor of size [N, C, H, W] and labels [N]\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_csv, train = True , img_transform=None):\n",
    "        \"\"\"\n",
    "        Dataset init function\n",
    "        \n",
    "        INPUT:\n",
    "        data_csv: Path to csv file containing [data, labels]\n",
    "        train: \n",
    "            True: if the csv file has [labels,data] (Train data and Public Test Data) \n",
    "            False: if the csv file has only [data] and labels are not present.\n",
    "        img_transform: List of preprocessing operations need to performed on image. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_csv = data_csv\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train\n",
    "        \n",
    "        data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            images = data.iloc[:,1:].to_numpy()\n",
    "            labels = data.iloc[:,0].astype(int)\n",
    "        else:\n",
    "            images = data.iloc[:,:]\n",
    "            labels = None\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        print(\"Total Images: {}, Data Shape = {}\".format(len(self.images), images.shape))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of samples in the dataset\"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"nimages (Tensor of shape [1,C,H,W]) and labels (Tensor of labels [1]).\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        image = np.array(image).astype(np.uint8).reshape((32, 32, 3),order=\"F\")\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        ##print(image)\n",
    "        image = self.img_transform(image)\n",
    "        \n",
    "        sample = {\"images\": image, \"labels\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cd43199-7b15-41bf-8c5a-a2af0d286b91",
   "metadata": {
    "id": "8cd43199-7b15-41bf-8c5a-a2af0d286b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 60000, Data Shape = (60000, 3072)\n",
      "Total Images: 4000, Data Shape = (4000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Data Loader Usage\n",
    "\n",
    "BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
    "NUM_WORKERS = 20 # Number of threads to be used for image loading. Adjust accordingly.\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.ToPILImage(),\n",
    "                                 transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
    "                         transforms.RandomHorizontalFlip(),\n",
    "                         transforms.ToTensor(), \n",
    "                         transforms.Normalize(*stats,inplace=True)])\n",
    "test_tfms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor(), transforms.Normalize(*stats)])\n",
    "\n",
    "# Train DataLoader\n",
    "train_data = \"../CIFAR/train_data.csv\" # Path to train csv file\n",
    "# train_data = \"/mnt/scratch1/siy197580/COL341/cifar/train_data.csv\"\n",
    "# test_data = \"/mnt/scratch1/siy197580/COL341/cifar/public_test.csv\"\n",
    "train_dataset = ImageDataset(data_csv = train_data, train=True, img_transform=train_tfms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "# Test DataLoader\n",
    "test_data = \"../CIFAR/public_test.csv\" # Path to test csv file\n",
    "# train_data = \"/mnt/scratch1/siy197580/COL341/cifar/train_data.csv\"\n",
    "# test_data = \"/mnt/scratch1/siy197580/COL341/cifar/public_test.csv\"\n",
    "test_dataset = ImageDataset(data_csv = test_data, train=True, img_transform=test_tfms)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "wjF2UTQVd_Y7",
   "metadata": {
    "id": "wjF2UTQVd_Y7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ZMCU1S6M1fmy",
   "metadata": {
    "id": "ZMCU1S6M1fmy"
   },
   "outputs": [],
   "source": [
    "# for b,s in enumerate(train_loader):\n",
    "#   print(s['images'])\n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e62bb43-ce19-4bc9-908b-2d83f4cebbbd",
   "metadata": {
    "id": "7e62bb43-ce19-4bc9-908b-2d83f4cebbbd"
   },
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = Sequential(\n",
    "            Conv2d(3, 32, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            #MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.res1 = Sequential(\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv2 = Sequential(\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.conv3 = Sequential(\n",
    "            Conv2d(64, 256, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.res2 = Sequential(\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(inplace=True),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv4 = Sequential(\n",
    "            Conv2d(256, 512, kernel_size=3, stride=1,padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=7,stride=7),\n",
    "            #Conv2d(512, 1024, kernel_size=3, stride=1,padding=1),\n",
    "            #ReLU(inplace=True),\n",
    "            #MaxPool2d(kernel_size=4,stride=4),\n",
    "        )\n",
    "\n",
    "        self.linear1 = Sequential(\n",
    "            Linear(512 * 1 * 1, 256),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(p=0.2),\n",
    "            Linear(256,10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res1(x)+x\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.res2(x)+x\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        #x = self.drop(x)\n",
    "        #x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "G4snUxabqqNP",
   "metadata": {
    "id": "G4snUxabqqNP"
   },
   "outputs": [],
   "source": [
    "def train_model(x_train,y_train):\n",
    "    #model.train()\n",
    "    tr_loss = 0\n",
    "    x_train, y_train = Variable(x_train), Variable(y_train)\n",
    "  \n",
    "    if torch.cuda.is_available():     # converting the data into GPU format\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "    \n",
    "    # Gradient clipping\n",
    "    # if grad_clip: \n",
    "    # torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "        \n",
    "    optimizer.zero_grad()             # clearing the Gradients of the model parameters\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train)\n",
    "    \n",
    "    # computing the training and validation loss\n",
    "    loss_train = loss(output_train, y_train)\n",
    "    #print(loss_train)\n",
    "  \n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "\n",
    "    return tr_loss\n",
    "\n",
    "def predict_model(x_test,y_test):\n",
    "   \n",
    "    if torch.cuda.is_available():     # converting the data into GPU format\n",
    "        x_test = x_test.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      output = model(x_test)\n",
    "    \n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "    #pred = np.append(pred,predictions)\n",
    "\n",
    "    #print(predictions,y_test.cpu().detach().numpy())\n",
    "    \n",
    "    return (np.sum(predictions==y_test.cpu().detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "NUzjVi9zp7CV",
   "metadata": {
    "id": "NUzjVi9zp7CV"
   },
   "outputs": [],
   "source": [
    "#torch.manual_seed(51)\n",
    "model = Net()\n",
    "\n",
    "#optimizer = SGD(model.parameters(),momentum=0.9,lr=0.1,nesterov=True)\n",
    "#Adam(model.parameters(),lr=1e-3)\n",
    "#SGD(model.parameters(),lr=0.1,momentum=0.9,weight_decay=4e-5,nesterov=True)\n",
    "loss = CrossEntropyLoss()\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9,nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss = loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bc83d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2681674\n",
      "Model's state_dict:\n",
      "conv1.0.weight \t torch.Size([32, 3, 3, 3])\n",
      "conv1.0.bias \t torch.Size([32])\n",
      "conv1.1.weight \t torch.Size([32])\n",
      "conv1.1.bias \t torch.Size([32])\n",
      "conv1.1.running_mean \t torch.Size([32])\n",
      "conv1.1.running_var \t torch.Size([32])\n",
      "conv1.1.num_batches_tracked \t torch.Size([])\n",
      "res1.0.weight \t torch.Size([32, 32, 3, 3])\n",
      "res1.0.bias \t torch.Size([32])\n",
      "res1.1.weight \t torch.Size([32])\n",
      "res1.1.bias \t torch.Size([32])\n",
      "res1.1.running_mean \t torch.Size([32])\n",
      "res1.1.running_var \t torch.Size([32])\n",
      "res1.1.num_batches_tracked \t torch.Size([])\n",
      "res1.3.weight \t torch.Size([32, 32, 3, 3])\n",
      "res1.3.bias \t torch.Size([32])\n",
      "res1.4.weight \t torch.Size([32])\n",
      "res1.4.bias \t torch.Size([32])\n",
      "res1.4.running_mean \t torch.Size([32])\n",
      "res1.4.running_var \t torch.Size([32])\n",
      "res1.4.num_batches_tracked \t torch.Size([])\n",
      "conv2.0.weight \t torch.Size([64, 32, 3, 3])\n",
      "conv2.0.bias \t torch.Size([64])\n",
      "conv2.1.weight \t torch.Size([64])\n",
      "conv2.1.bias \t torch.Size([64])\n",
      "conv2.1.running_mean \t torch.Size([64])\n",
      "conv2.1.running_var \t torch.Size([64])\n",
      "conv2.1.num_batches_tracked \t torch.Size([])\n",
      "conv3.0.weight \t torch.Size([256, 64, 3, 3])\n",
      "conv3.0.bias \t torch.Size([256])\n",
      "conv3.1.weight \t torch.Size([256])\n",
      "conv3.1.bias \t torch.Size([256])\n",
      "conv3.1.running_mean \t torch.Size([256])\n",
      "conv3.1.running_var \t torch.Size([256])\n",
      "conv3.1.num_batches_tracked \t torch.Size([])\n",
      "res2.0.weight \t torch.Size([256, 256, 3, 3])\n",
      "res2.0.bias \t torch.Size([256])\n",
      "res2.1.weight \t torch.Size([256])\n",
      "res2.1.bias \t torch.Size([256])\n",
      "res2.1.running_mean \t torch.Size([256])\n",
      "res2.1.running_var \t torch.Size([256])\n",
      "res2.1.num_batches_tracked \t torch.Size([])\n",
      "res2.3.weight \t torch.Size([256, 256, 3, 3])\n",
      "res2.3.bias \t torch.Size([256])\n",
      "res2.4.weight \t torch.Size([256])\n",
      "res2.4.bias \t torch.Size([256])\n",
      "res2.4.running_mean \t torch.Size([256])\n",
      "res2.4.running_var \t torch.Size([256])\n",
      "res2.4.num_batches_tracked \t torch.Size([])\n",
      "conv4.0.weight \t torch.Size([512, 256, 3, 3])\n",
      "conv4.0.bias \t torch.Size([512])\n",
      "linear1.0.weight \t torch.Size([256, 512])\n",
      "linear1.0.bias \t torch.Size([256])\n",
      "linear1.3.weight \t torch.Size([10, 256])\n",
      "linear1.3.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(pytorch_total_params)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pCqCbQQasykP",
   "metadata": {
    "id": "pCqCbQQasykP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.4941234838962556 0.5115 50.379576683044434\n",
      "2 1.0656916590531667 0.63725 36.1342031955719\n",
      "3 0.9057798973719279 0.71475 49.394920110702515\n",
      "4 0.811916120449702 0.72375 49.38152575492859\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "epochs = 15\n",
    "#grad_clip = 0.1 \n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "loss_file = open('loss_nest_1e-1_lr.txt','w')\n",
    "acc_file = open('accuracy_nest_1e-1_lr.txt','w')\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_train_loss = 0\n",
    "    acc = 0\n",
    "    n = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "      images = sample['images']\n",
    "      labels = sample['labels']\n",
    "      avg_train_loss += train_model(images,labels)\n",
    "      scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    for b,sample in enumerate(test_loader):\n",
    "      images = sample['images']\n",
    "      labels = sample['labels']\n",
    "      n += len(labels)\n",
    "      acc += predict_model(images,labels)\n",
    "\n",
    "\n",
    "    avg_train_loss /= len(train_loader)\n",
    "    acc /= n\n",
    "    loss_file.write('{}\\n'.format(avg_train_loss))\n",
    "    losses.append(avg_train_loss)\n",
    "    acc_file.write('{}\\n'.format(acc))\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(epoch+1,avg_train_loss,acc,time.time()-st)\n",
    "    st = time.time()\n",
    "\n",
    "loss_file.close()\n",
    "acc_file.close()\n",
    "\n",
    "#time.time()-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afqEJO8R30Mr",
   "metadata": {
    "id": "afqEJO8R30Mr"
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['figure.figsize'] = (15,15)\n",
    "\n",
    "x = [i+1 for i in range(epochs)]\n",
    "y= losses\n",
    "\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Cross-Entropy Loss\")\n",
    "plt.title('Training Loss v/s Epochs (CIFAR10)')\n",
    "\n",
    "plt.plot(x,y,'-mo')\n",
    "plt.savefig('c10plt.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GLqZ77KZ4D55",
   "metadata": {
    "id": "GLqZ77KZ4D55"
   },
   "outputs": [],
   "source": [
    "y = accs\n",
    "\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title('Test Accuracy v/s Epochs (CIFAR10)')\n",
    "\n",
    "\n",
    "plt.plot(x,y,'-mo')\n",
    "plt.savefig('c10plt1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rkkX0XEPN4V1",
   "metadata": {
    "id": "rkkX0XEPN4V1"
   },
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zcWDHUc6Kk7X",
   "metadata": {
    "id": "zcWDHUc6Kk7X"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./model4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K6nVF9ZVLKCn",
   "metadata": {
    "id": "K6nVF9ZVLKCn"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)\n",
    "\"\"\"\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd123d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
