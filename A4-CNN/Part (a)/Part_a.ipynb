{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77e38e-e3a2-4a16-b8fc-dbf088c2afd0",
   "metadata": {
    "id": "cf77e38e-e3a2-4a16-b8fc-dbf088c2afd0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#import cv2\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74132880-fc8a-4517-a038-95786bda75b2",
   "metadata": {
    "id": "74132880-fc8a-4517-a038-95786bda75b2"
   },
   "outputs": [],
   "source": [
    "# DataLoader Class\n",
    "# if BATCH_SIZE = N, dataloader returns images tensor of size [N, C, H, W] and labels [N]\n",
    "class DevanagariDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_csv, train = True , img_transform = None):\n",
    "        \"\"\"\n",
    "        Dataset init function\n",
    "        \n",
    "        INPUT:\n",
    "        data_csv: Path to csv file containing [data, labels]\n",
    "        train: \n",
    "            True: if the csv file has [data, labels] (Train data and Public Test Data) \n",
    "            False: if the csv file has only [data] and labels are not present.\n",
    "        img_transform: List of preprocessing operations need to performed on image. \n",
    "        \"\"\"\n",
    "        self.data_csv = data_csv\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train\n",
    "        \n",
    "        data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            images = data.iloc[:,:-1].to_numpy()\n",
    "            labels = data.iloc[:,-1].astype(int)\n",
    "        else:\n",
    "            images = data.iloc[:,:]\n",
    "            labels = None\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        print(\"Total Images: {}, Data Shape = {}\".format(len(self.images), images.shape))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of samples in the dataset\"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads image of the given index and performs preprocessing.\n",
    "        \n",
    "        INPUT: \n",
    "        idx: index of the image to be loaded.\n",
    "        \n",
    "        OUTPUT:\n",
    "        sample: dictionary with keys images (Tensor of shape [1,C,H,W]) and labels (Tensor of labels [1]).\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        image = np.array(image).astype(np.uint8).reshape(32, 32, 1)\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        image = self.img_transform(image)\n",
    "#         print(image.shape, label, type(image))\n",
    "        sample = {\"images\": image, \"labels\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c044f-5f52-4800-9b9c-9e8259644fd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f9c044f-5f52-4800-9b9c-9e8259644fd5",
    "outputId": "5de7252d-769f-4aed-dc3a-ec741f9946d2"
   },
   "outputs": [],
   "source": [
    "# Data Loader Usage\n",
    "\n",
    "BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
    "NUM_WORKERS = 20 # Number of threads to be used for image loading. Adjust accordingly.\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "\n",
    "# Train DataLoader\n",
    "train_data = \"../nishant/devanagari/train_data_shuffled.csv\" # Path to train csv file\n",
    "train_dataset = DevanagariDataset(data_csv = train_data, train=True, img_transform=img_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "# Test DataLoader\n",
    "test_data = \"../nishant/devanagari/public_test.csv\" # Path to test csv file\n",
    "test_dataset = DevanagariDataset(data_csv = test_data, train=True, img_transform=img_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wjF2UTQVd_Y7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjF2UTQVd_Y7",
    "outputId": "7bb620fb-c4a6-4bf3-de1d-ab1599a4a9cb"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62bb43-ce19-4bc9-908b-2d83f4cebbbd",
   "metadata": {
    "id": "7e62bb43-ce19-4bc9-908b-2d83f4cebbbd"
   },
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = Sequential(\n",
    "            Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.conv2 = Sequential(\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.conv3 = Sequential(\n",
    "            Conv2d(64, 256, kernel_size=3, stride=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=1),\n",
    "        )\n",
    "\n",
    "        self.conv4 = Sequential(\n",
    "            Conv2d(256, 512, kernel_size=3, stride=1),\n",
    "            ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.linear1 = Sequential(\n",
    "            Linear(512 * 1 * 1, 256),\n",
    "            ReLU(inplace=True),\n",
    "        )\n",
    "        self.drop = Dropout(p=0.2)\n",
    "        self.linear2 = Linear(256,46)\n",
    "        \n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G4snUxabqqNP",
   "metadata": {
    "id": "G4snUxabqqNP"
   },
   "outputs": [],
   "source": [
    "def train_model(epoch,x_train,y_train):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    x_train, y_train = Variable(x_train), Variable(y_train)\n",
    "  \n",
    "    if torch.cuda.is_available():     # converting the data into GPU format\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()             # clearing the Gradients of the model parameters\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train)\n",
    "    \n",
    "    # computing the training and validation loss\n",
    "    loss_train = loss(output_train, y_train)\n",
    "    #print(loss_train)\n",
    "  \n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "\n",
    "    return tr_loss\n",
    "\n",
    "def predict_model(x_test,y_test):\n",
    "   \n",
    "    with torch.no_grad():\n",
    "      output = model(x_test.cuda())\n",
    "    \n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "    #print(predictions,y_test.cpu().detach().numpy())\n",
    "    \n",
    "    return (np.sum(predictions==y_test.cpu().detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NUzjVi9zp7CV",
   "metadata": {
    "id": "NUzjVi9zp7CV"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(51)\n",
    "model = Net()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "loss = CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss = loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pCqCbQQasykP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCqCbQQasykP",
    "outputId": "694106cf-3145-4441-c6ca-e12d965af4e8"
   },
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "loss_file = open('dloss.txt','w')\n",
    "losses = []\n",
    "acc_file = open('daccuracy.txt','w')\n",
    "accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_train_loss = 0\n",
    "    acc = 0\n",
    "    n = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "      images = sample['images']\n",
    "      labels = sample['labels']\n",
    "      avg_train_loss += train_model(epoch,images,labels)\n",
    "\n",
    "    model.eval()\n",
    "    for b,sample in enumerate(test_loader):\n",
    "      images = sample['images']\n",
    "      labels = sample['labels']\n",
    "      n += len(labels)\n",
    "      acc += predict_model(images,labels)\n",
    "\n",
    "\n",
    "    avg_train_loss /= len(train_loader)\n",
    "    acc /= n\n",
    "    loss_file.write('{}\\n'.format(avg_train_loss))\n",
    "    losses.append(avg_train_loss)\n",
    "    acc_file.write('{}\\n'.format(acc))\n",
    "    accs.append(acc)\n",
    "    print(epoch+1,avg_train_loss,acc)\n",
    "\n",
    "loss_file.close()\n",
    "acc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afqEJO8R30Mr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "afqEJO8R30Mr",
    "outputId": "2a15711a-f185-4346-8946-024456fcaaf9"
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['figure.figsize'] = (15,15)\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8]\n",
    "y= [1.366287866974121,\n",
    "0.33299428693321353,\n",
    "0.19497612236863207,\n",
    "0.1334356545754101,\n",
    "0.10036742397586403,\n",
    "0.07695268875326189,\n",
    "0.06064676735883631,\n",
    "0.04936345100945905]\n",
    "\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Cross-Entropy Loss\")\n",
    "plt.title('Training Loss v/s Epochs (DEVANAGARI)')\n",
    "\n",
    "plt.plot(x,y,'-mo')\n",
    "plt.savefig('dplt.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GLqZ77KZ4D55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "GLqZ77KZ4D55",
    "outputId": "2907e030-6c81-42ff-d3b9-ee18af1b4708"
   },
   "outputs": [],
   "source": [
    "y = [0.9028260869565218,\n",
    "0.9447826086956522,\n",
    "0.9634782608695652,\n",
    "0.97,\n",
    "0.975,\n",
    "0.9776086956521739,\n",
    "0.9778260869565217,\n",
    "0.9806521739130435\n",
    "]\n",
    "\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title('Test Accuracy v/s Epochs (DEVANAGARI)')\n",
    "\n",
    "\n",
    "plt.plot(x,y,'-mo')\n",
    "plt.savefig('dplt1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tET7uFrW8Afs",
   "metadata": {
    "id": "tET7uFrW8Afs"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./model.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Devanagari.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
