{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c6f614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:09:59.970443Z",
     "iopub.status.busy": "2021-11-03T16:09:59.968923Z",
     "iopub.status.idle": "2021-11-03T16:10:03.474682Z",
     "shell.execute_reply": "2021-11-03T16:10:03.473135Z"
    },
    "papermill": {
     "duration": 3.521721,
     "end_time": "2021-11-03T16:10:03.474985",
     "exception": false,
     "start_time": "2021-11-03T16:09:59.953264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from sklearn.model_selection import KFold\n",
    "import torchvision.models as models\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainfile = \"../input/col341-a3/training.csv\"#sys.argv[1]\n",
    "testfile = \"../input/col341-a3/test.csv\"#sys.argv[2]\n",
    "modelfile = \"model.pth\"#sys.argv[3]\n",
    "lossfile = \"loss.txt\"#sys.argv[4]\n",
    "accuracyfile = \"accuracy.txt\"#sys.argv[5]\n",
    "img_train_folder=\"../input/col341-a3/\"\n",
    "img_test_folder=\"../input/col341-a3/\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b84cd89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.521144Z",
     "iopub.status.busy": "2021-11-03T16:10:03.520341Z",
     "iopub.status.idle": "2021-11-03T16:10:03.525800Z",
     "shell.execute_reply": "2021-11-03T16:10:03.526377Z"
    },
    "papermill": {
     "duration": 0.036456,
     "end_time": "2021-11-03T16:10:03.526584",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.490128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform = None, train=True):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.is_train = train\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.class2index = {\n",
    "        \"Virabhadrasana\":0,\n",
    "        \"Vrikshasana\":1,\n",
    "        \"Utkatasana\":2,\n",
    "        \"Padahastasana\":3,\n",
    "        \"Katichakrasana\":4,\n",
    "        \"TriyakTadasana\":5,\n",
    "        \"Gorakshasana\":6,\n",
    "        \"Tadasana\":7,\n",
    "        \"Natarajasana\":8,                 \n",
    "        \"Pranamasana\":9,\n",
    "        \"ParivrittaTrikonasana\":10,\n",
    "        \"Tuladandasana\":11,\n",
    "        \"Santolanasana\":12,\n",
    "        \"Still\":13,\n",
    "        \"Natavarasana\":14,\n",
    "        \"Garudasana\":15,\n",
    "        \"Naukasana\":16,\n",
    "        \"Ardhachakrasana\":17,\n",
    "        \"Trikonasana\":18,\n",
    "\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df[\"name\"].iloc[index]\n",
    "        if self.is_train:\n",
    "            label = self.class2index[self.df[\"category\"].iloc[index]]\n",
    "        else:\n",
    "            label = -1\n",
    "        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        sample = {\"images\": image, \"labels\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4668af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.560991Z",
     "iopub.status.busy": "2021-11-03T16:10:03.560323Z",
     "iopub.status.idle": "2021-11-03T16:10:03.637736Z",
     "shell.execute_reply": "2021-11-03T16:10:03.637208Z"
    },
    "papermill": {
     "duration": 0.09793,
     "end_time": "2021-11-03T16:10:03.637880",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.539950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Loader Usage\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "NUM_WORKERS = 20\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.Resize(size=(64,64)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(*stats,inplace=True)])\n",
    "\n",
    "img_test_transforms = transforms.Compose([transforms.Resize(size=(64,64)),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(*stats)])\n",
    "\n",
    "\n",
    "train_data = trainfile \n",
    "train_dataset = CustomDataset(csv_path = train_data, images_folder = img_train_folder, transform=img_transforms, train=True)\n",
    "\n",
    "test_data = testfile \n",
    "test_dataset = CustomDataset(csv_path = test_data, images_folder = img_test_folder, transform=img_test_transforms, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcb50e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.671651Z",
     "iopub.status.busy": "2021-11-03T16:10:03.669925Z",
     "iopub.status.idle": "2021-11-03T16:10:03.672644Z",
     "shell.execute_reply": "2021-11-03T16:10:03.673085Z"
    },
    "papermill": {
     "duration": 0.022484,
     "end_time": "2021-11-03T16:10:03.673221",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.650737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#architecture 1 \n",
    "\n",
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 32, kernel_size=3, stride=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            Conv2d(64, 512, kernel_size=3, stride=1),\n",
    "            BatchNorm2d(512),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            Conv2d(512, 1024, kernel_size=2, stride=1),\n",
    "            #BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            #MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(1024 * 1 * 1 , 256),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(p = 0.2),\n",
    "            Linear(256 * 1 * 1 , 19),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772401a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.708828Z",
     "iopub.status.busy": "2021-11-03T16:10:03.707612Z",
     "iopub.status.idle": "2021-11-03T16:10:03.710426Z",
     "shell.execute_reply": "2021-11-03T16:10:03.709958Z"
    },
    "papermill": {
     "duration": 0.0274,
     "end_time": "2021-11-03T16:10:03.710573",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.683173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#architecture 2\n",
    "\n",
    "class Net_drop_1(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net_drop_1, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            \n",
    "            Conv2d(3, 32, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(p = 0.2),\n",
    "            \n",
    "            Conv2d(32, 64, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout(p = 0.2),\n",
    "            \n",
    "            Conv2d(64, 128, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout(p = 0.2),\n",
    "            \n",
    "            Conv2d(128, 128, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout(p = 0.2),\n",
    "            \n",
    "            Conv2d(128, 256, kernel_size=3, stride=1,padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout(p = 0.2),\n",
    "            \n",
    "            Conv2d(256, 512, kernel_size=3, stride=1,padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(p = 0.2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(512*4*4 , 512),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(p = 0.2),\n",
    "            Linear(512, 64),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(p = 0.2),\n",
    "            Linear(64 , 19),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3d6191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.739663Z",
     "iopub.status.busy": "2021-11-03T16:10:03.738987Z",
     "iopub.status.idle": "2021-11-03T16:10:03.741293Z",
     "shell.execute_reply": "2021-11-03T16:10:03.741719Z"
    },
    "papermill": {
     "duration": 0.019761,
     "end_time": "2021-11-03T16:10:03.741857",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.722096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pretrained arch\n",
    "\n",
    "class Pre_Net(Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Pre_Net,self).__init__()\n",
    "        \n",
    "        self.m = models.googlenet(pretrained=True)\n",
    "        self.m.fc = nn.Linear(self.m.fc.in_features, 19)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.m(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197ae632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.770849Z",
     "iopub.status.busy": "2021-11-03T16:10:03.769301Z",
     "iopub.status.idle": "2021-11-03T16:10:03.771452Z",
     "shell.execute_reply": "2021-11-03T16:10:03.771912Z"
    },
    "papermill": {
     "duration": 0.019521,
     "end_time": "2021-11-03T16:10:03.772050",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.752529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch, x, y, criterion, optimizer, model):\n",
    "    model.train()\n",
    "    \n",
    "    x_train, y_train = Variable(x), Variable(y)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output_train = model(x_train)\n",
    "    \n",
    "    loss_train = criterion(output_train, y_train)\n",
    "    \n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    \n",
    "    return tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147d1bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.798007Z",
     "iopub.status.busy": "2021-11-03T16:10:03.797314Z",
     "iopub.status.idle": "2021-11-03T16:10:03.799984Z",
     "shell.execute_reply": "2021-11-03T16:10:03.799522Z"
    },
    "papermill": {
     "duration": 0.017758,
     "end_time": "2021-11-03T16:10:03.800089",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.782331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(epoch, x, y, criterion, optimizer, model):\n",
    "    \n",
    "    model.eval()\n",
    "    x_train, y_train = Variable(x), Variable(y)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "\n",
    "    output_train = model(x_train)\n",
    "    output_train = torch.argmax(output_train, dim = 1)\n",
    "    \n",
    "    return (torch.sum(output_train==y_train)).item()/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5426acbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.825754Z",
     "iopub.status.busy": "2021-11-03T16:10:03.824152Z",
     "iopub.status.idle": "2021-11-03T16:10:03.826443Z",
     "shell.execute_reply": "2021-11-03T16:10:03.826948Z"
    },
    "papermill": {
     "duration": 0.017147,
     "end_time": "2021-11-03T16:10:03.827094",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.809947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_n(x, model):\n",
    "    \n",
    "    model.eval()\n",
    "    x_train= Variable(x)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        \n",
    "    output_train = model(x_train)\n",
    "    output_train = torch.argmax(output_train, dim = 1)\n",
    "    return output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f226c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.852922Z",
     "iopub.status.busy": "2021-11-03T16:10:03.851980Z",
     "iopub.status.idle": "2021-11-03T16:10:03.853945Z",
     "shell.execute_reply": "2021-11-03T16:10:03.854369Z"
    },
    "papermill": {
     "duration": 0.017112,
     "end_time": "2021-11-03T16:10:03.854492",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.837380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    \n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3454941d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:03.882660Z",
     "iopub.status.busy": "2021-11-03T16:10:03.881990Z",
     "iopub.status.idle": "2021-11-03T16:10:06.816930Z",
     "shell.execute_reply": "2021-11-03T16:10:06.816407Z"
    },
    "papermill": {
     "duration": 2.952037,
     "end_time": "2021-11-03T16:10:06.817057",
     "exception": false,
     "start_time": "2021-11-03T16:10:03.865020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946259\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                  train_dataset, \n",
    "                  batch_size=BATCH_SIZE, num_workers = NUM_WORKERS, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "              test_dataset,\n",
    "              batch_size=BATCH_SIZE,  num_workers = NUM_WORKERS, shuffle = False)\n",
    "\n",
    "torch.manual_seed(51)\n",
    "cnnmodel = Net_drop_1()\n",
    "#cnnmodel.apply(reset_weights)\n",
    "torch.cuda.empty_cache()\n",
    "print(sum(p.numel() for p in cnnmodel.parameters()))\n",
    "\n",
    "optimizer = SGD(cnnmodel.parameters(), lr=0.1, momentum=0.9,nesterov=True)\n",
    "criterion = CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer,  max_lr = 0.1, epochs = 20, steps_per_epoch = len(train_loader))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cnnmodel = cnnmodel.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57e5a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:10:06.847749Z",
     "iopub.status.busy": "2021-11-03T16:10:06.847015Z",
     "iopub.status.idle": "2021-11-03T16:37:52.278964Z",
     "shell.execute_reply": "2021-11-03T16:37:52.279601Z"
    },
    "papermill": {
     "duration": 1665.451609,
     "end_time": "2021-11-03T16:37:52.279805",
     "exception": false,
     "start_time": "2021-11-03T16:10:06.828196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss -> Epoch0 2.8025729541909206\n",
      "Training loss -> Epoch1 2.1325618167446083\n",
      "Training loss -> Epoch2 1.6446180139502433\n",
      "Training loss -> Epoch3 1.2959100934740615\n",
      "Training loss -> Epoch4 1.0329184785281142\n",
      "Training loss -> Epoch5 2.2757302473669183\n",
      "Training loss -> Epoch6 1.2564059528585982\n",
      "Training loss -> Epoch7 0.9581721388313869\n",
      "Training loss -> Epoch8 0.8372493770024548\n",
      "Training loss -> Epoch9 0.7277268623448399\n",
      "Training loss -> Epoch10 0.6372433658944417\n",
      "Training loss -> Epoch11 0.5919598249131686\n",
      "Training loss -> Epoch12 0.5426453788803048\n",
      "Training loss -> Epoch13 0.5023631251429859\n",
      "Training loss -> Epoch14 0.4760413686808658\n",
      "Training loss -> Epoch15 0.42449328670762987\n",
      "Training loss -> Epoch16 0.3963466780132627\n",
      "Training loss -> Epoch17 0.3653552824350661\n",
      "Training loss -> Epoch18 0.35703242906171523\n",
      "Training loss -> Epoch19 0.3347140775597973\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    loss_avg = 0\n",
    "    count = 0\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        images = sample['images']\n",
    "        labels = sample['labels']\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        loss = train(epoch, images, labels, criterion, optimizer, cnnmodel)\n",
    "        loss_avg += loss\n",
    "        count+=1\n",
    "        scheduler.step()\n",
    "        \n",
    "    loss_avg = loss_avg/count\n",
    "    print(\"Training loss -> Epoch\" + str(epoch), loss_avg)\n",
    "\n",
    "    torch.save(cnnmodel.state_dict(), modelfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f1e345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:37:52.323419Z",
     "iopub.status.busy": "2021-11-03T16:37:52.322417Z",
     "iopub.status.idle": "2021-11-03T16:38:17.596608Z",
     "shell.execute_reply": "2021-11-03T16:38:17.597890Z"
    },
    "papermill": {
     "duration": 25.301002,
     "end_time": "2021-11-03T16:38:17.598106",
     "exception": false,
     "start_time": "2021-11-03T16:37:52.297104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "              test_dataset,\n",
    "              batch_size=BATCH_SIZE,  num_workers = NUM_WORKERS, shuffle = False)\n",
    "\n",
    "predictions = torch.Tensor([])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    predictions = predictions.cuda()\n",
    "    \n",
    "for batch_idx, sample in enumerate(test_loader):\n",
    "    images = sample['images']\n",
    "    \n",
    "    temp = predict_n(images, cnnmodel)\n",
    "    predictions = torch.cat((predictions,temp),0)\n",
    "\n",
    "predictions=predictions.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18504be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T16:38:17.662639Z",
     "iopub.status.busy": "2021-11-03T16:38:17.655141Z",
     "iopub.status.idle": "2021-11-03T16:38:17.768883Z",
     "shell.execute_reply": "2021-11-03T16:38:17.768147Z"
    },
    "papermill": {
     "duration": 0.143562,
     "end_time": "2021-11-03T16:38:17.769056",
     "exception": false,
     "start_time": "2021-11-03T16:38:17.625494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classif = {\n",
    "        \"Virabhadrasana\":0,\n",
    "        \"Vrikshasana\":1,\n",
    "        \"Utkatasana\":2,\n",
    "        \"Padahastasana\":3,\n",
    "        \"Katichakrasana\":4,\n",
    "        \"TriyakTadasana\":5,\n",
    "        \"Gorakshasana\":6,\n",
    "        \"Tadasana\":7,\n",
    "        \"Natarajasana\":8,                 \n",
    "        \"Pranamasana\":9,\n",
    "        \"ParivrittaTrikonasana\":10,\n",
    "        \"Tuladandasana\":11,\n",
    "        \"Santolanasana\":12,\n",
    "        \"Still\":13,\n",
    "        \"Natavarasana\":14,\n",
    "        \"Garudasana\":15,\n",
    "        \"Naukasana\":16,\n",
    "        \"Ardhachakrasana\":17,\n",
    "        \"Trikonasana\":18,\n",
    "\n",
    "        }\n",
    "    \n",
    "inv_map = {v: k for k, v in classif.items()}\n",
    "\n",
    "pred = [inv_map[letter] for letter in predictions]\n",
    "df1 = pd.read_csv(testfile)\n",
    "df1[\"category\"] = pred\n",
    "df1.drop(df1.tail(1).index,inplace=True)\n",
    "df1.to_csv(path_or_buf=\"submission.csv\", columns=[\"name\", \"category\"],index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1706.651636,
   "end_time": "2021-11-03T16:38:19.321297",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-03T16:09:52.669661",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
